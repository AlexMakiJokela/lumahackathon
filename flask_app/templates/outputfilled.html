<!doctype html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Voice-Driven Video Generator</title>
	<link href="style.css" type="text/css" rel="stylesheet" />
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Faculty+Glyphic&family=Ubuntu:ital,wght@0,300;0,400;0,500;0,700;1,300;1,400;1,500;1,700&display=swap" rel="stylesheet">
	
</head>
<body>
	<div class="container">
		<h3 class="subtitle">The World's Best </h3>
	<h1>Personal Emotion Imaginator</h1>
	<form method="post" id="main-form">
		<!-- Hidden fields to store data -->
		<input type="hidden" name="voice_emotion" id="voice_emotion">
		<input type="hidden" name="text_block" id="text_block">
		<input type="hidden" name="emotion_index" id="emotion_index" value="0">
		<input type="hidden" name="all_emotions" id="all_emotions" value="[]">
	</form>

	<div class="recording-section">
		<h2>Record your voice for emotional analysis</h2>
		<p class="q"><em>How you feel right now in this moment?</em></p>
		
		<div class="buttoncontainer">
		<button id="start-record">Start Recording</button>
		<button id="stop-record" disabled>Stop Recording</button>
		</div>
		<p><em>Please speak clearly and honestly and <br>
		I'll make a video for you based on your emotions.</em></p>
		<p id="recording-status" class="status q">Video extended successfully!</p>
	</div>
	
	<!-- Container for displaying the text block -->
	<div id="text-block-container" class="text-block" style="display: block;">
		<h2>Generated Video Description</h2>
		<div id="text-block-content">
			<ul>
				<li><strong>Image used:</strong> <a href="https://www.michaeldivine.com/wp-content/uploads/2021/01/Apsara5-2.jpg">[Image Title]</a></li>
				<li><strong>Emotional transition:</strong> Awkwardness</li>
				<li><strong>End keyframe prompt:</strong> transform the reference image into a  semi-abstract scene depicting profound Awkwardness</li>
				<li><strong>Video prompt:</strong> draw a smooth, dreamy transition that swirl and evolves towards a  semi-abstract scene depicting profound Awkwardness, high detail, detail evolves intricately and dynamically over time</li>
			</ul>
				<h3>View your video <a href="https://storage.cdn-luma.com/dream_machine/9d333c98-4ade-4b59-b5d3-1339b2dbef15/33fa1ceb-eb24-43ea-a7cd-ca47a57808f0_result41bca6283cc0bad6.mp4">Here</a></h3></div>
		
		<div class="controls">
			<button id="extend-button" style="display: inline-block;">Extend This Video</button>
			<button id="reset-button" style="display: inline-block;">Start New Video</button>
		</div>
	</div>

	<!-- Container for video history -->
	<div id="video-history-container" class="video-history" style="display: block;">
		<h1>Your Video Journey</h1>
		<div id="video-entries">
			<div class="video-entry">
			
			<h3 class="accordion"><strong>Video 1:</strong> to Excitement to Determination</h3>
			
			<div class="panel"><div id="text-block-content">
				<ul>
					<li><strong>Image used:</strong> <a href="https://www.michaeldivine.com/wp-content/uploads/2021/01/Apsara5-2.jpg">[Image Title]</a></li>
					<li><strong>Emotional transition:</strong> Awkwardness</li>
					<li><strong>End keyframe prompt:</strong> transform the reference image into a  semi-abstract scene depicting profound Awkwardness</li>
					<li><strong>Video prompt:</strong> draw a smooth, dreamy transition that swirl and evolves towards a  semi-abstract scene depicting profound Awkwardness, high detail, detail evolves intricately and dynamically over time</li>
				</ul>
					</div>
				</div></div><div class="video-entry">
	
	<h3 class="accordion"><strong>Video 2:</strong> Interest</h3>
	
	<div class="panel"><p>Reference image url: https://www.michaeldivine.com/wp-content/uploads/2021/01/Apsara5-2.jpg
<strong>Emotion</strong>al <strong>transition</strong>: Interest
End keyframe prompt: transform the reference image into a  semi-abstract <strong>scene</strong> depicting profound Interest
Video prompt: draw a smooth, dreamy <strong>transition</strong> that swirl and evolves towards a  semi-abstract <strong>scene</strong> depicting profound Interest, high detail, detail evolves intricately and dynamically over time
View your video here: https://storage.cdn-luma.com/dream_machine/17ff77cc-a7c7-4485-b1ce-f6099b46c186/1ca3ef2c-1c02-49b4-b12e-1c73843bea9a_result270164906226b36d.mp4</p></div></div><div class="video-entry">
	
	<h3 class="accordion"><strong>Video 3:</strong> Anger</h3>
	
<div class="panel"><p>Reference image url: https://www.michaeldivine.com/wp-content/uploads/2021/01/Apsara5-2.jpg
<strong>Emotion</strong>al <strong>transition</strong>: Anger
End keyframe prompt: transform the reference image into a  semi-abstract <strong>scene</strong> depicting profound Anger
Video prompt: draw a smooth, dreamy <strong>transition</strong> that swirl and evolves towards a  semi-abstract <strong>scene</strong> depicting profound Anger, high detail, detail evolves intricately and dynamically over time
View your video here: https://storage.cdn-luma.com/dream_machine/1b705a78-8f82-44b4-926d-9ae6cf58906c/9d6f153e-92aa-4155-b9f8-3ea948db1f7e_result14f7efa791207c81.mp4</p></div></div><div class="video-entry">
	
	<h3 class="accordion"><strong>Video 4:</strong> Contempt</h3>
	
	<div class="panel"><p>Reference image url: https://www.michaeldivine.com/wp-content/uploads/2021/01/Apsara5-2.jpg
<strong>Emotion</strong>al <strong>transition</strong>: Contempt
End keyframe prompt: transform the reference image into a  semi-abstract <strong>scene</strong> depicting profound Contempt
Video prompt: draw a smooth, dreamy <strong>transition</strong> that swirl and evolves towards a  semi-abstract <strong>scene</strong> depicting profound Contempt, high detail, detail evolves intricately and dynamically over time
View your video here: https://storage.cdn-luma.com/dream_machine/5e00ec78-a579-4baa-a9f4-ab63fb4be349/9f4d2b34-65aa-4250-be04-a3451c3d53bb_resulta86da1fae1ce9668.mp4</p></div></div></div>
	</div>
	</div>
	<script>
		let recorder, audioStream;
		let videoDetails = null;
		let allEmotions = [];
		let currentEmotionIndex = 2; // Start at 2 because the first video already uses emotions 0 and 1
		
		const statusElem = document.getElementById('recording-status');
		const emotionElem = document.getElementById('emotion-result');
		const startButton = document.getElementById('start-record');
		const stopButton = document.getElementById('stop-record');
		const textBlockContainer = document.getElementById('text-block-container');
		const textBlockContent = document.getElementById('text-block-content');
		const extendButton = document.getElementById('extend-button');
		const resetButton = document.getElementById('reset-button');
		const videoHistoryContainer = document.getElementById('video-history-container');
		const videoEntries = document.getElementById('video-entries');
		
		// Initialize video history as empty (don't load from local storage)
		let videoHistory = [];
		
		function displayVideoHistory() {
			if (videoHistory.length === 0) {
				videoHistoryContainer.style.display = 'none';
				return;
			}
			
			// Clear previous entries
			videoEntries.innerHTML = '';
			
			// Add each video entry
			videoHistory.forEach((entry, index) => {
				const videoEntry = document.createElement('div');
				videoEntry.className = 'video-entry';
				
				const title = document.createElement('h3');
				title.textContent = `Video ${index + 1}: ${entry.emotion}`;
				
				const description = document.createElement('div');
				description.innerHTML = formatTextBlock(entry.textBlock);
				
				videoEntry.appendChild(title);
				videoEntry.appendChild(description);
				videoEntries.appendChild(videoEntry);
			});
			
			videoHistoryContainer.style.display = 'block';
		}
		
		function formatTextBlock(text) {
			if (!text) return '';
			
			// Replace newlines with paragraph breaks
			let formatted = text.split('\n\n').map(para => `<p>${para}</p>`).join('');
			
			// Format any headings (assuming headings might be lines ending with a colon)
			formatted = formatted.replace(/<p>([^<:]+):<\/p>/g, '<h4>$1:</h4>');
			
			// Highlight key terms
			formatted = formatted.replace(/(emotions?|feelings?|scenes?|transitions?|movements?|colors?|lights?|sounds?)/gi, 
				'<strong>$1</strong>');
			
			return formatted;
		}
		
		// Handle extending the video
		extendButton.addEventListener('click', function() {
			// Show "Processing..." status
			statusElem.textContent = 'Extending video...';
			
			// Save current video to history before extending
			const currentEmotion = document.getElementById('voice_emotion').value;
			const currentTextBlock = document.getElementById('text_block').value;
			
			if (currentEmotion && currentTextBlock) {
				videoHistory.push({
					emotion: currentEmotion,
					textBlock: currentTextBlock
				});
				
				// Update video history display
				displayVideoHistory();
			}
			
			// Call the extend endpoint
			fetch('/extend_video', {
				method: 'POST',
				headers: {
					'Content-Type': 'application/json',
				},
				body: JSON.stringify({
					previous_emotion: document.getElementById('voice_emotion').value,
					emotion_index: currentEmotionIndex,
					all_emotions: allEmotions
				}),
			})
			.then(response => {
				if (!response.ok) {
					return response.json().then(data => {
						throw new Error(data.error || `HTTP error! Status: ${response.status}`);
					});
				}
				return response.json();
			})
			.then(data => {
				if (data.error) {
					throw new Error(data.error);
				}
				
				// Update current emotion index if provided
				if (data.current_emotion_index !== undefined) {
					currentEmotionIndex = data.current_emotion_index;
					document.getElementById('emotion_index').value = currentEmotionIndex;
					console.log(`Updated emotion index to: ${currentEmotionIndex}`);
				}
				
				// Display emotion result
				emotionElem.textContent = `New Emotion: ${data.emotion}`;
				
				// Set the hidden field value for emotion
				document.getElementById('voice_emotion').value = data.emotion;
				
				// Display text block if available
				if (data.text_block) {
					textBlockContent.innerHTML = formatTextBlock(data.text_block);
					textBlockContainer.style.display = 'block';
					
					// Also set hidden field for form submission
					document.getElementById('text_block').value = data.text_block;
				}
				
				// Display video link if available
				if (data.video_url) {
					const videoLink = document.getElementById('video-link');
					videoLink.href = data.video_url;
					document.getElementById('video-link-container').style.display = 'block';
				}
				
				statusElem.textContent = 'Video extended successfully!';
			})
			.catch(error => {
				console.error('Error:', error);
				emotionElem.textContent = 'Error: ' + error.message;
				statusElem.textContent = 'Failed to extend video. Try again?';
			});
		});
		
		// Reset button - start a new video
		resetButton.addEventListener('click', function() {
			resetForNewRecording();
		});
	
		startButton.onclick = function() {
			startRecording();
		};
		
		async function startRecording() {
			resetForNewRecording();
			
			try {
				// Clear previous results
				emotionElem.textContent = '';
				textBlockContainer.style.display = 'none';
				textBlockContent.textContent = '';
				extendButton.style.display = 'none';
				resetButton.style.display = 'none';
				statusElem.textContent = 'Accessing microphone...';
				
				// Get audio stream with quality settings
				audioStream = await navigator.mediaDevices.getUserMedia({ 
					audio: {
						echoCancellation: true,
						noiseSuppression: true,
						autoGainControl: true
					} 
				});
				
				// Create audio recorder with settings for better quality
				const options = { 
					audioBitsPerSecond: 128000,  // 128 kbps
					mimeType: 'audio/webm'
				};
				
				recorder = new MediaRecorder(audioStream, options);
				
				let chunks = [];
				recorder.ondataavailable = e => {
					if (e.data.size > 0) chunks.push(e.data);
				};
				
				recorder.onstop = () => {
					processSoundRecording(chunks);
				};
				
				// Start recording - get data in chunks of 1 second
				recorder.start(1000);
				
				// Update UI
				startButton.disabled = true;
				stopButton.disabled = false;
				statusElem.textContent = 'Recording... Speak clearly about how you feel.';
				
			} catch (err) {
				console.error('Microphone access error:', err);
				statusElem.textContent = 'Error: Could not access your microphone. Please check permissions.';
			}
		}
		
		function resetForNewRecording() {
			// Reset emotion index and clear previous data
			currentEmotionIndex = 2; // Start at 2 because the first video already uses emotions 0 and 1
			allEmotions = [];
			document.getElementById('emotion_index').value = "2";
			document.getElementById('all_emotions').value = "[]";
			
			// Clear video history
			videoHistory = [];
			videoHistoryContainer.style.display = 'none';
			videoEntries.innerHTML = '';
			
			// Clear UI elements
			emotionElem.textContent = '';
			textBlockContainer.style.display = 'none';
			textBlockContent.textContent = '';
			extendButton.style.display = 'none';
			resetButton.style.display = 'none';
		}
		
		function processSoundRecording(chunks) {
			statusElem.textContent = 'Processing audio...';
			
			// Create audio blob from chunks
			const audioBlob = new Blob(chunks, { type: 'audio/webm' });
			
			// Create a File object with a proper name
			const audioFile = new File([audioBlob], 'recording.wav', { type: 'audio/wav' });
			
			// Create FormData and append the file
			const formData = new FormData();
			formData.append('audio_file', audioFile);
			
			// Send to the server
			statusElem.textContent = 'Uploading and analyzing audio (this may take a moment)...';
			fetch('/upload_audio', {
				method: 'POST',
				body: formData
			})
			.then(response => {
				if (!response.ok) {
					return response.json().then(data => {
						throw new Error(data.error || `HTTP error! Status: ${response.status}`);
					});
				}
				return response.json();
			})
			.then(data => {
				if (data.error) {
					throw new Error(data.error);
				}
				
				// Store all emotions for later use
				if (data.all_emotions && Array.isArray(data.all_emotions)) {
					allEmotions = data.all_emotions;
					document.getElementById('all_emotions').value = JSON.stringify(allEmotions);
				}
				
				// Display emotion result
				emotionElem.textContent = `Detected Emotion: ${data.emotion}`;
				
				// Set the hidden field value for emotion
				document.getElementById('voice_emotion').value = data.emotion;
				
				// Display text block if available
				if (data.text_block) {
					textBlockContent.innerHTML = formatTextBlock(data.text_block);
					textBlockContainer.style.display = 'block';
					extendButton.style.display = 'inline-block';
					resetButton.style.display = 'inline-block';
					
					// Also set hidden field for form submission
					document.getElementById('text_block').value = data.text_block;
				}
				
				// Display video link if available
				if (data.video_url) {
					const videoLink = document.getElementById('video-link');
					videoLink.href = data.video_url;
					document.getElementById('video-link-container').style.display = 'block';
				}
				
				statusElem.textContent = 'Analysis complete!';
			})
			.catch(error => {
				console.error('Error:', error);
				emotionElem.textContent = 'Error: ' + error.message;
				statusElem.textContent = 'Analysis failed. Try again?';
			});
		}
	
		stopButton.onclick = function() {
			if (recorder && recorder.state !== 'inactive') {
				statusElem.textContent = 'Stopping recording...';
				recorder.stop();
			}
			
			if (audioStream) {
				audioStream.getTracks().forEach(track => track.stop());
			}
			
			// Update UI
			startButton.disabled = false;
			stopButton.disabled = true;
		};
		
		var acc = document.getElementsByClassName("accordion");
		var i;
		
		for (i = 0; i < acc.length; i++) {
		  acc[i].addEventListener("click", function() {
			this.classList.toggle("active");
			var panel = this.nextElementSibling;
			if (panel.style.display === "block") {
			  panel.style.display = "none";
			} else {
			  panel.style.display = "block";
			}
		  });
		}
		
	</script>

</body></html>